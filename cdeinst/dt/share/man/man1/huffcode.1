'\" t
...\" huffcode.sgm /main/7 1996/09/08 19:53:22 rws $
.de P!
.fl
\!!1 setgray
.fl
\\&.\"
.fl
\!!0 setgray
.fl			\" force out current output buffer
\!!save /psv exch def currentpoint translate 0 0 moveto
\!!/showpage{}def
.fl			\" prolog
.sy sed -e 's/^/!/' \\$1\" bring in postscript file
\!!psv restore
.
.de pF
.ie     \\*(f1 .ds f1 \\n(.f
.el .ie \\*(f2 .ds f2 \\n(.f
.el .ie \\*(f3 .ds f3 \\n(.f
.el .ie \\*(f4 .ds f4 \\n(.f
.el .tm ? font overflow
.ft \\$1
..
.de fP
.ie     !\\*(f4 \{\
.	ft \\*(f4
.	ds f4\"
'	br \}
.el .ie !\\*(f3 \{\
.	ft \\*(f3
.	ds f3\"
'	br \}
.el .ie !\\*(f2 \{\
.	ft \\*(f2
.	ds f2\"
'	br \}
.el .ie !\\*(f1 \{\
.	ft \\*(f1
.	ds f1\"
'	br \}
.el .tm ? font underflow
..
.ds f1\"
.ds f2\"
.ds f3\"
.ds f4\"
.ta 8n 16n 24n 32n 40n 48n 56n 64n 72n 
.TH "huffcode" "user cmd"
.SH "NAME"
\fBhuffcode\fP \(em Create optimized DtSearch compression/decompression tables
.SH "SYNOPSIS"
.PP
\fBhuffcode\fP [-l\fIlit_thresh\fP  | -l- ]  [-o] \fIhuffile\fP  [\fItextfile\fP] 
.SH "DESCRIPTION"
.PP
\fBhuffcode\fP creates optimized DtSearch
compression/decompression tables\&.
.PP
Documents stored in a DtSearch database text repository can be first
compressed using a Huffman text compression algorithm\&. The algorithm
provides optimal compression only with preanalysis of the statistical
distribution of bytes in the database corpus\&.
\fBhuffcode\fP analyses a text corpus and generates
DtSearch compression and decompression tables\&. It is provided as a
convenience utility for database developers who want to optimize offline
storage requirements\&. Compression is not used in databases created
without the ability to store text in a DtSearch repository\&.
.PP
\fBhuffcode\fP reads a text file as input and writes out
\fBophuf\&.huf\fP (compression or "encode" table) and
\fBophuf\&.c\fP (decompression or "decode" table)\&.
\fBophuf\&.huf\fP is an external ascii file that also
retains the statistical information on how it was generated\&.
\fBhuffcode\fP can be executed repeatedly against different
text samples, continually accumulating results\&. In the case of a small
or static text corpus, the entire corpus can be fed into
\fBhuffcode\fP for optimal huffman compression\&. In large or
dynamic databases the typical practice is to feed
dynamic f representative text samples\&.
.PP
The huffman code tables are created once for each API instance (not once
per database) before any documents are loaded\&. The only program to read
the encode table, an external file, is \fBdtsrload\fP\&. The
\fBophuf\&.huf\fP file generated by
\fBhuffcode\fP should be used instead of the provided
default file prior to the first run of \fBdtsrload\fP for
any databases to be accessed by a particular API instance\&. The decode
table, a C module, should be compiled and linked into the application
code ahead of the API library to override the default decode module in
the library\&. Huf files and decode modules are not user editable\&.
.SS "HCTREE_ID"
.PP
It is imperative that the encode and decode tables reflect identical
byte statistics to prevent decode errors\&. The first line of
\fBophuf\&.huf\fP includes a long integer value named
\fBHCTREE_ID\fP\&. Each execution of
\fBhuffcode\fP generates a new, unique
\fBhctree_id\fP integer\&. \fBdtsrload\fP loads
this integer into the database configuration and status record when it
loads the first document into a new database\&. Thereafter, each execution
of \fBdtsrload\fP for that database confirms that the same
\fBhctree_id\fP is used for each document compression\&. It
will abort if the \fBophuf\&.huf\fP
\fBhctree_id\fP does not match the value for a database
from previous executions\&.
.PP
\fBhctree_id\fP is also stored as a variable in the decode
module \fBophuf\&.c\fP\&. \fBDtSearchInit\fP
will not open any database listed in the ocf file whose
\fBhctree_id\fP, as stored in its configuration and status
record, does not match the value in the decode module\&. The
\fBdtsrdbrec\fP utility will print the
\fBhctree_id\fP value for any database\&.
.SH "OPTIONS"
.PP
The following options are available:
.PP
.RS
\fBNote:  
.PP
If an option takes a value, the value must be directly appended to
the option name without white space\&.
.RE
.IP "\fB-l\fP\fIlit_thresh\fP" 10
Sets the literal character\&'s minimum threshold to the integer specified
by \fIlit_thresh\fP\&.
.IP "" 10
This Huffman algorithm implements a pseudo-character called the literal
character\&. It represents all characters whose frequency is so low that
no huffman translation will be attempted\&. This reduces the maximum
length of the coded bit string when there are lots of zero- or
low-frequency bytes in the text corpus\&. For example, pure ASCII text
files only occasionally have byte values less than 32 (control
characters) and rarely greater than 127 (high order bit turned on)\&. The
\fIlit_thresh\fP value specifies the literal
character\&'s threshold count\&. After counting is completed, any character
in the encode table occurring with frequency less than or equal to
\fIlit_thresh\fP will be coded with the
literal character\&.
.IP "" 10
If this option and the \fB-l-\fP option are
omitted, the default is \fB-l0\fP, meaning that
literal coding is provided only for bytes that never occur (counts of
zero)\&.
.IP "\fB-l-\fP" 10
Disables literal character encoding\&. Disabling literal character
encoding in corpa with unbalanced byte frequency distributions will lead
to extremely long bit string codes\&. Most natural language text corpa
are represented by highly unbalanced frequency distributions so this
option is not recommended for most DtSearch applications\&.
.IP "" 10
If this option and the \fB-l\fP\fIlit_thresh\fP option are omitted, the default is
\fB-l0\fP, meaning that literal coding is provided
only for bytes that never occur (counts of zero)\&.
.IP "\fB-o\fP" 10
Suppresses the overwrite prompt\&. It preauthorizes erasure and
reinitialization of the decode module\&.
.IP "\fItextfile\fP" 10
Specifies an optional input file of text that is representative of the
entire text corpus of the databases\&. It should contain bytes in the same
relative abundances as occur in documents in the entire corpus\&. Since
\fBhuffcode\fP can be executed repeatedly with different
document \fItextfile\fPs, it is possible to
analyze the entire actual corpus if it is small enough or static\&.
.IP "" 10
If \fItextfile\fP is not specified, the byte
frequencies in the currently loaded tables are not changed, and the
huffman codes are recomputed with the existing frequencies\&. This is
useful for examining the relative merits of using different literal
character thresholds\&.
.SH "OPERANDS"
.PP
The required input file name (\fIhuffile\fP)
is the base file name of the encode table, excluding the
\fB\&.huf\fP extension\&. \fBdtsrload\fP expects
\fIhuffile\fP to be
\fBophuf\fP\&. Similarly, the decode module will be named
\fIhuffile\fP\&.c\&.
.PP
At the beginning of each new execution, \fBhuffcode\fP
tries to open the encode table file and continue byte frequency counting
from the last run\&. If the huf file represented by
\fIhuffile\fP does not exist, the table\&'s counts are
initialized to zeroes\&. The decode module is recomputed fresh each run,
whether it existed before or not\&.
.SH "ENVIRONMENT VARIABLES"
.PP
None\&.
.SH "RESOURCES"
.PP
None\&.
.SH "ACTIONS/MESSAGES"
.PP
None\&.
.SH "RETURN VALUES"
.PP
The return values are as follows:
.IP "0" 10
\fBhuffcode\fP completed successfully\&.
.IP "nonzero" 10
\fBhuffcode\fP encountered an error\&.
.SH "FILES"
.PP
\fBhuffcode\fP reads the specified
\fIhuffile\fP\&. It also reads
\fItextfile\fP if it is
specified\&.
It writes to
\fIhuffile\fP\&.huf and
\fIhuffile\fP\&.c\&.
.SH "EXAMPLES"
.PP
Read \fBophuf\&.huf\fP if it exists and initialize the
internal byte count table with its byte frequency counts\&. If
\fBophuf\&.huf\fP does not exist, the internal byte counts
will be initialized to zeros\&. The encoding table in the original huf
file will be discarded\&. The text file \fBfoo\&.txt\fP will
be read and its individual byte frequencies added to the internal byte
count table\&. Then, \fBophuf\&.huf\fP will be written out,
with an encoding scheme based on the current byte counts, and with a
literal character encoding all bytes that have zero frequency\&. Finally,
if the decode module \fBophuf\&.c\fP already exists, a
prompt requesting permission to overwrite it will be output to stdout
and, if an affirmative response is read from stdin, a new version
corresponding to the new \fBophuf\&.huf\fP will be written
out\&.
.PP
.nf
\f(CWhuffcode ophuf foo\&.txt\fR
.fi
.PP
.PP
Read \fBmyappl\&.huf\fP and initialize the internal byte
count table with its byte frequency counts\&. Since no
\fBtextfile\fP argument is specified, the only possible
action is to build different coding tables using existing frequency
counts in \fBmyappl\&.huf\fP\&. The new tables will be based
on a literal character implementation where only bytes that occur more
than 200 times will be given an encoding; all other bytes will be
encoded with the literal character\&. After new encoding tables are
generated \fBmyappl\&.huf\fP will be written out\&. The
decode module \fBmyappl\&.c\fP will also be written out
without prompting whether it preexists or not\&.
.PP
.nf
\f(CWhuffcode -l200 -o myappl\fR
.fi
.PP
.SH "SEE ALSO"
.PP
\fBdtsrcreate\fP(1),
\fBdtsrdbrec\fP(1),
\fBdtsrload\fP(1),
\fBDtSrAPI\fP(3),
\fBDtSearch\fP(5)
...\" created by instant / docbook-to-man, Sun 02 Sep 2012, 09:40
